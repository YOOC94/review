1、谈谈你对数据倾斜的认识：什么是数据倾斜、现象哪些
数据倾斜：某个task处理的数据量太多了，导致这个task比其他task要慢很多或者跑不下来
造成某个task处理的数据量太多，我碰到过2种场景：
（1）数据中本身某个key对应的值太多了，造成shuffle之后，处理该key的task任务明显异常
（2）有些任务需要人为的分区，比如sparksql的jdbc读大表，需要指定数据的upperBound和lowerBound以及numPartition
从而spark帮我们确认每个分区的数据步长。如果这个numPartition没有正确设置，每个分区的步长可能相差很大，也会造成某个Task
跑的特别慢


2、请分别使用MapReduce和Hive实现如下几种场景如何解决数据倾斜
a）大表和小表join
b）group by
c）大表和大表join

自己造出倾斜的数据，以及提供三种场景的数据倾斜的解决思路以及MR和Hive的代码实现
https://www.cnblogs.com/juncaoit/p/6078039.html

3、描述我们的离线数仓项目中的存在的问题有哪些？以及改进思路

flume采集日志数据的聚合后，日志是由一个single agent来处理的，高可用怎么保证。解决思路：https://blog.csdn.net/lzxlfly/article/details/80672267
ip2region.db这个db文件的更新问题
数据中出现的脏数据，目前能知道脏数据有几条，但没有把他存起来，以备后期审核。这个用spark就能搞定，filter算子过滤出脏数据之后存起来


4、Azkaban中调度mr作业的时候，我们使用的是hadoop命令的完整路径，要将命令改成${hadoop.home}/bin/hadoop ... 这种方式提交，那么hadoop.home如何配置才能生效
